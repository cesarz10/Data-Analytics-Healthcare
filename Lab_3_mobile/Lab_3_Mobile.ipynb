{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msf80JUdx_K5"
   },
   "source": [
    "### Submission guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5itxjxy2x_Bh"
   },
   "source": [
    "1. Fill in your name in the notebook in the top cell.\n",
    "2. Fill in the gaps in the code where indicated. <br> Make sure that you:<br> - fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" <br> - **do not leave any `raise NotImplementedErrors`** in the code\n",
    "3. Do **NOT change the variable names**, however, you can add comments in the code.\n",
    "4. Do **NOT remove any of the cells** of the notebook!\n",
    "5. Discussion is allowed, but every student needs to hand a personal version of the lab. Plagiarism will be sanctioned!   \n",
    "6. Before submitting, restart your kernel & **make sure that every cell runs**.<br>Code that doesn't run will not be scored.<br>The notebooks with all source code, and optional extra files need to be handed in using Ufora.<br> Make sure all your notebooks are already executed when you upload them (i.e. there should be output after the cells). \n",
    "7. **Zip** your lab assignment folder and name the archive: `Surname_Name.zip` <br> Keep the same folder structure as the provided lab assignment!<br><span style='color: red'>Do not rename any of the notebooks or files</span>!<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HcGF1HroxbCA"
   },
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6mm49VPx99v"
   },
   "source": [
    "Final tip: make sure you have answered every question and filled in all the required code by running through the notebook and searching for YOUR ANSWER HERE and YOUR CODE HERE!\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You have to install for this lab some additional python packages. In the requirements.txt file, we provided all the necessary packages. If you use pip as package manager, you can install all the packages using the following command:\n",
    "`pip install -r requirements.txt`. If you use conda as package manager, you can use the following command: `conda install -c conda-forge --file requirements.txt`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the primary data analysis libraries\n",
    "import plotly.graph_objects as go; import numpy as np\n",
    "from plotly_resampler import FigureResampler, FigureWidgetResampler\n",
    "from tsfresh import extract_features\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from plotly.offline import init_notebook_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvBVZzaTyPpF"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM9XxmHfyTnk"
   },
   "source": [
    "# Lab: Mobile\n",
    "\n",
    "This lab will focus on mobile or time series data.\n",
    "You can use the experience of the previous pandas lab to manipulate, clean or vizualize parts of the available data. \n",
    "\n",
    "Note that all exercises in this lab are meant to be solved using the provided Python packages. Avoid coding functionality that is available in other packages beside the one mentioned above.\n",
    "\n",
    "Modern mobile phones come equipped with a variety of sensors that can be used to capture and analyze various aspects of the phone's environment. These sensors include accelerometers, gyroscopes, magnetometers, GPS receivers, microphones, cameras, and proximity sensors. These sensors can be used to gather data over a period of time and analyze how the phone's behaviour changes over time. \n",
    "\n",
    "<img src=\"https://www.mdpi.com/sensors/sensors-19-02164/article_deploy/html/images/sensors-19-02164-g002.png\"\n",
    "     alt=\"Phone sensors\"\n",
    "     width=\"750\" />\n",
    "\n",
    "Mobile phone sensors can be incredibly useful in a healthcare context, as they allow for the collection of real-time, high-quality data that can be used to monitor patients and track their progress over time. For example, accelerometers and gyroscopes can be used to track a patient's movements and detect changes in their activity levels, which can be useful in managing chronic conditions like Parkinson's disease. GPS receivers can be used to track a patient's location, which can be useful in cases where patients have cognitive impairments or are prone to wandering. Additionally, microphones can be used to monitor a patient's breathing patterns and detect signs of respiratory distress, while cameras can be used to monitor a patient's skin for signs of pressure ulcers. Overall, the use of mobile phone sensors in healthcare can help to improve patient outcomes, reduce the cost of care, and enable more personalized and effective treatment plans.\n",
    "\n",
    "These sensor data are inherently time series data because they capture information about changes in the phone's environment over time. In a time series context, these data points are arranged in chronological order, with each observation representing a snapshot of the phone's environment at a particular point in time. It is by analyzing these data points over time, researchers and developers can gain insights into how the phone's environment changes over time and how users interact with their devices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BypvbhIdzxpL"
   },
   "source": [
    "## Part 1: univariate time series\n",
    "\n",
    "An univariate time series is a set of observations that measures changes in a single variable over time. In other words, it is a time series that tracks only one metric or data point over time. Univariate time series analysis involves analyzing the patterns and trends in this data over time, such as detecting seasonality, identifying trends, and forecasting future values. By focusing on a single variable, univariate time series analysis can provide valuable insights into the behavior of that variable over time, which can be useful for a wide range of applications.\n",
    "\n",
    "The light sensor in a smartphone is such a univariate time series. It is a component that detects the ambient light levels surrounding the device. This sensor is typically located on the front of the phone near the earpiece, and it is used to automatically adjust the screen brightness based on the surrounding light conditions. \n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/2VirYjC48RA/maxresdefault.jpg\"\n",
    "     alt=\"Sound sensors\"\n",
    "     width=\"400\" />\n",
    "\n",
    "The light sensor works by measuring the intensity of light (measured in Lux) that falls on its surface and converting it into an electrical signal that can be processed by the phone's software. This signal is a univariate timeseries that represents the variation in light intensity over time. \n",
    "\n",
    "The data produced by the light sensor can be used for a variety of purposes, beyond determining when to turn on the phone's screen or adjusting the color temperature of the display to reduce eye strain. Overall, the light sensor is an important component of modern smartphones, and it plays a key role in improving the user experience by providing more accurate and responsive adjustments to the device's display settings.\n",
    "\n",
    "**In this first part, you will analyse and investigate a light signal recorded from a smartphone's light sensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Time series Data Exploration\n",
    "\n",
    "within the assignment folder, you will find a file with *light.json* containing sound values captured from a mobile phone. Try to read this data in a Pandas dataframe. You can use the *pandas.read_json* functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hPuEbt-KyOrI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>elapsed_seconds</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1672566284559000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1672566286165000000</td>\n",
       "      <td>1.606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1672566287651000000</td>\n",
       "      <td>3.092</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1672566289046000000</td>\n",
       "      <td>4.487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1672566290365000000</td>\n",
       "      <td>5.806</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1672566497016000000</td>\n",
       "      <td>212.457</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1672566498094000000</td>\n",
       "      <td>213.535</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1672566499174000000</td>\n",
       "      <td>214.615</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1672566500272000000</td>\n",
       "      <td>215.713</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1672566501367000000</td>\n",
       "      <td>216.808</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  elapsed_seconds  value\n",
       "0   1672566284559000000            0.000      0\n",
       "1   1672566286165000000            1.606      3\n",
       "2   1672566287651000000            3.092      3\n",
       "3   1672566289046000000            4.487      2\n",
       "4   1672566290365000000            5.806      4\n",
       "..                  ...              ...    ...\n",
       "80  1672566497016000000          212.457      3\n",
       "81  1672566498094000000          213.535      4\n",
       "82  1672566499174000000          214.615      3\n",
       "83  1672566500272000000          215.713      2\n",
       "84  1672566501367000000          216.808      3\n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/light.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe generated from this json datafile contains three columns: 'time', 'elapsed_seconds' and 'value'.\n",
    "Every row indicate a value in our time series signal. Combining all these signals together represents our time series data.\n",
    "\n",
    "We will transform the 'time' column later in this lab. The 'elapsed_seconds' provides us already with some notion of time. It shows for every row the time relative in seconds, when it was generated given the start time at row index 0.\n",
    "\n",
    "By looking at the last row in this dataframe, you can see the total duration of our time series signal.<br>\n",
    "**What is the total duration in minutes? Try to give a programmatic answer by using the dataframe and e.g. the max() function** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1474294416.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    total_duration = # YOUR CODE HERE\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "total_duration = # YOUR CODE HERE\n",
    "\n",
    "print('The total duration in minutes is: {}'.format(round(total_duration,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"value\" column. As indicated in the text above these values are represented in Lux, a measure of the amount of light that falls on a surface. It is calculated by dividing the total light output of a source by the area over which it is distributed. In other words, Lux is a measure of the brightness of light that is perceived by the human eye.\n",
    "\n",
    "Based on the different Lux ranges, one can try to understand where the person uses its smartphone. The table below provides you with a table defining the different Lux ranges in a diverse set of environments.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/303294764/figure/tbl1/AS:614070734561285@1523417280413/Lux-level-estimates.png\"\n",
    "     alt=\"Sound sensors\"\n",
    "     width=\"400\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the max() function to get the largest Lux level in our time series data and intrepret this value based on the table above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lux = # YOUR CODE HERE\n",
    "interpretation = \"# YOUR TEXT HERE\"\n",
    "\n",
    "print('The max Lux level is: {} and this corresponds to a {} environment'.format(max_lux, interpretation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, when working with time series data, it might be interesting to plot the obtained values in function of their timestamp.<br>\n",
    "\n",
    "**Plot the Lux values in our dataframe in function of their 'elapsed_seconds'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwNzo4RIz69c"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(15, 5))\n",
    "\n",
    "# YOUR CODE HERE, REPLACE NONE VALUES\n",
    "axes.plot(None, None, label=\"Lux\")\n",
    "\n",
    "axes.set_title(\"Univariate Signal\")\n",
    "axes.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you interpret this signal? <br>\n",
    "**Describe the signal and explain what happens with the smartphone in your own words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = \"\"\"\n",
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When recording this light signal from our smartphone, we hade to define a sampling rate. The sample rate (or sampling rate) is the number of samples taken per second. By explicitly stating this sampling rate in our smartphone application, we can calculate the number of expected samples over a larger period.\n",
    "\n",
    "**We have set the sample rate for our light sensor to 0.5Hz (1 sample every 2 seconds). What is the total amount of samples that we expect in our dataset? You can use the math.ceil function to round the possible float value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_samples = # YOUR CODE HERE\n",
    "\n",
    "print('The the total amount of expected samples is: {}'.format(expected_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this value with the provided amount of samples. **How many samples are missing?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_samples = # YOUR CODE HERE\n",
    "missing = expected_samples-amount_samples\n",
    "\n",
    "print(\"{} samples are missing from this dataset\".format(missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What could the possible cause of this mismatch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2 = \"\"\"\n",
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the sample rate of the obtained signal**<br> \n",
    "You can use the inverse of the mean difference (diff) between the 'elapsed_seconds'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = # YOUR CODE HERE\n",
    "\n",
    "print('The sample rate of the obtained signal is: {}'.format(sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our signal to be represented as an 0.5Hz time series as all logic built on top of this signal expects this sample rate. We therefore will upsample the amount of samples and try to deal with the missing data. Upsampling a dataframe in Pandas is an easy operation when the index column of the Pandas dataframe is represented as timestamp.\n",
    "\n",
    "Currently, this is not the case, and all other columns are integer or floating point values. We will have to convert the time column first to a timestamp. The 'time' column provides the UNIX time, also known as POSIX time. It is a system for representing time as the number of seconds that have elapsed since January 1, 1970, at 00:00:00 UTC. It is a standardized way for computers to track and compare time and is commonly used in programming and operating systems.\n",
    "\n",
    "What we want, is a UTC timestamp. UTC timestamp represents time in a standardized format that is based on the international time standard, Coordinated Universal Time (UTC). UTC timestamps are usually represented as a string of characters that includes the year, month, day, hour, minute, and second of a specific time, and optionally, the milliseconds, microseconds, or nanoseconds.\n",
    "\n",
    "Online you can find converters between UNIX and UTC, such as https://www.unixtimestamp.com/ <br>\n",
    "\n",
    "**Copy and paste the first UNIX timestamp of our dataset in this online converter. When (year, month, day, hour & minutes) was the start of this signal? Keep in mind that this signal was generated in Belgium**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer3=\"\"\"\n",
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The online converter above (https://www.unixtimestamp.com/) also provides you with additional information, such as format of the UNIX time.\n",
    "\n",
    "Python and Pandas provide you a way to transform these unix times to their human interpretable format. <br>\n",
    "**Transform the 'time' column, representing the UNIX time, to UTC timestamp. Take a look at the pandas to_datetime function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_utc'] = # YOUR CODE HERE\n",
    "\n",
    "df['time_utc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "2JUlFnESpoIm",
    "outputId": "1e4153c6-8c04-4477-b730-ea31caf9e736"
   },
   "source": [
    "Keep in mind that this UTC timestamps will report the Greenwich time (UTC: 0). \n",
    "\n",
    "**Transform the timestamps within the time_utc to represent the time in Belgium. (you can use the tz_convert and tz_localize Pandas functions). To easily access datetimelike properties, take a look at pandas.Series.dt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to localise first to Greenwich time and then convert to the local time in Belgium\n",
    "df['time_belgium'] = # YOUR CODE HERE\n",
    "\n",
    "df['time_belgium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have human-readable timestamp within our dataframe, **we can set it as index in our dataframe and make a plot of the Lux values in function of the human readable time. Verify the difference in x-axis between this plot and the previous signal plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the local time as index\n",
    "\n",
    "df.index = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(15, 5))\n",
    "# Now, let's plot the lux values\n",
    "\n",
    "# YOUR CODE HERE, REPLACE NONE\n",
    "# NOTE: in the previous block, you've specified the index of the dataframe.\n",
    "# Matplotlib will take by default the index column of a dataframe as x-axis\n",
    "axes.plot(None,label='Lux')\n",
    "\n",
    "# set the title and show the legend\n",
    "axes.set_title(\"Univariate Signal\")\n",
    "axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still want our signal to be represented as an 0.5Hz time series. We have a valid time index column in our dataframe so we can now upsample the amount of samples and try to deal with the missing data. \n",
    "\n",
    "**Use the Pandas resample functionality and always keep the first value found. Warning: the resample function requires you to provide the sampling period instead of the sampling rate!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE, REPLACE NONE\n",
    "resampled = df.resample(None).first()\n",
    "\n",
    "resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recalculate the sample rate on this resampled dataframe, do you obtain a sample rate close to 0.5Hz?**\n",
    "You will have to calculate the sampling rate based on index. The difference between two human readable timestamp will provide you with a pandas.Timedelta. Use the total_seconds function on each Timedelta to get the total amount of elapsed seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the index values of the resampled dataframe that contain the new time values in a new Series\n",
    "\n",
    "index_values = resampled.index.to_series()\n",
    "\n",
    "# now use these index_values to calculate the sample rate\n",
    "sample_rate = # YOUR CODE HERE\n",
    "\n",
    "print('The sample rate of the resampled signal is: {}'.format(sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resampled dataframe in function of the elapsed_seconds before, what is the effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(15, 5))\n",
    "# Now, let's plot the lux values\n",
    "\n",
    "# YOUR CODE HERE, REPLACE NONE\n",
    "axes.plot(None,label='Lux')\n",
    "\n",
    "# set the title and show the legend\n",
    "axes.set_title(\"Univariate Signal\")\n",
    "axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want these gaps in our data. To solve this, we can interpolate the timeseries and fill the missing values. In a strict sense, a linear interpolation was already performed in the plot of original data. With our expertise about light signals, we know that a linear interpolation is not the best fit to deal with these missing values.\n",
    "\n",
    "**Use the Pandas interpolate function and try to fill in the gap as realistic as possible. Use an appropriate interpolation technique and explain why you would use this technique here. Make a plot to show that your interpolation function works** <br> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html#pandas-dataframe-interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled['interpolatede_value'] = resampled['value']...# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer4=\"\"\"\n",
    "I've use the following interpolation function: [x] because ...\n",
    "\"\"\"\n",
    "print(answer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(15, 5))\n",
    "\n",
    "# Now, let's plot the lux values\n",
    "\n",
    "# YOUR CODE HERE, REPLACE NONE with correct interpolatede_value\n",
    "axes.plot(None,label='Lux')\n",
    "\n",
    "# set the title and show the legend\n",
    "axes.set_title(\"Univariate Signal\")\n",
    "axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Time Series Feature Engeneering\n",
    "\n",
    "Now that we have cleaned our dataframe and provided a solution for the available missing data, we can introduce some concepts of feature engeneering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_signal = resampled['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many machine learning application, decisions are not made on individual sensor samples, but e.g. a classification task has to be performed in windows of X seconds or minutes. Within the context of time series data, this means that we buffer the data in such a window, calculate some interesting features based on this window and provide these features to a machine learning model per window. In a training phase, we have to create these windows by ourselves based on the provided larger signal.\n",
    "\n",
    "Pandas provides functionalities to create these windows based on the GroupBy on timestamps function.\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html <br>\n",
    "\n",
    "**Create windows with a frequency of 10s from the cleaned_signal dataframe. The groupby pandas function returns by default a SeriesGroupBy object of all groups. Show the table of the first 10s window from this object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a group object using SeriesGroupBy that has windows with a frequency of 10s\n",
    "groups = # YOUR CODE HERE\n",
    "\n",
    "#show first 10s window\n",
    "list(groups)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the amount of samples as expected in this first window?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer5=\"\"\"\n",
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "print(answer5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the mean and standard deviation for each 10s window of the above interpolated signal.** \n",
    "\n",
    "You can use the aggregator function to retrun one dataframe.\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily extract more features by extending the aggregator function (such as adding the min, max or custom functions). We will continue now with multivariate time series in the second part of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtwTwqvr3tMd"
   },
   "source": [
    "---\n",
    "## Part 2: Multivariate time series\n",
    "\n",
    "\n",
    "Multivariate time series data is a type of data that consists of multiple variables or features, each of which is measured over time. The smartphone accelerometer is such a multivariate sensor that measures the rate of change of the phone's velocity in three dimensions, providing information about the phone's movement.\n",
    "\n",
    "<img src=\"https://www.mathworks.com/help/supportpkg/android/ref/simulinkandroidsupportpackage_galaxys4_accelerometer.png\"  width=\"40%\">\n",
    "\n",
    "By collecting accelerometer data over time, we can generate a multivariate time series dataset that includes information about the acceleration in each of the X, Y, and Z directions at different points in time. This data can be used to analyze patterns in the movement of the smartphone, such as how often the user takes steps or changes direction or how fast they are moving. This type of data is useful in a variety of applications, such as activity recognition, gait analysis, and fall detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Time Series Data Exploration\n",
    "\n",
    "We have provided a sensor measurement from the accelerometer in the assignment folder. **Load the 'accelerometer.json' file and verify that indeed three axis (x,y,z) are available in this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = # YOUR CODE HERE\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have a 'elapsed_seconds' column in this dataframe. This can however be an interesting column to create by ourselves.\n",
    "\n",
    "**Create the 'elapsed_seconds' column. You can do this either by:**\n",
    "1) **Using the cummulative sum function from the differences between the UNIX times in the 'time' column. Take into account that these differences will be in nanoseconds and we want the elapsed_seconds**\n",
    "\n",
    "2) **Using the cummulative sum function from the differences between the UTC timestamps, generated from the UNIX 'time' column. Going from UNIX to UTC can be done similar as in part 1.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['elapsed_seconds'] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the total duration in minutes? Try to give a programmatic answer by using the 'elapsed_seconds' column  and e.g. the max() function** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration = # YOUR CODE HERE\n",
    "\n",
    "print('The total duration in minutes is: {}'.format(round(total_duration,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now plot the three axis of the accelerometer and investigate the signal based on the time series representation. We made all of our previous plots in matplotlib. In terms of possible interaction with the plot, matplotlib is somewhat limited..\n",
    "\n",
    "We provided the full code to plot this accelerometer in plotly using our own plotly-resampler. Plotly is a very intuitive plotting framework and provides tools for pannin and zooming in plots. It was however very slow when large amounts of data (read: time series data) had to be provided within these plots. Plotly-resampler resolve this issue by downsampling (aggregating) the data respective to the view and then plotting the aggregated points. When you interact with the plot (panning, zooming, ...), callbacks are used to aggregate data and update the figure.\n",
    "\n",
    "**Run the cell below and pan or zoom in the data to see the advantage of Ploty and Plotly-resampler. When you hover with you mouse on the plot, you will see an option panel on the top right that you can use. You can also select certain regions in the plot itself to change the view. The reset axes option can always be used to go back to the original full signal view.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureWidgetResampler(go.Figure())\n",
    "fig.add_trace(go.Scattergl(name='x', showlegend=True), hf_x=df['elapsed_seconds'], hf_y=df['x'])\n",
    "fig.add_trace(go.Scattergl(name='y', showlegend=True), hf_x=df['elapsed_seconds'], hf_y=df['y'])\n",
    "fig.add_trace(go.Scattergl(name='z', showlegend=True), hf_x=df['elapsed_seconds'], hf_y=df['z'])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accelermeter window is a representation of multiple human activities (standing, sitting, lying down, walking, jumping etc). Can you give a brief overview of the activities performed in this dataset? List them in your answer below and provide the start and end time for each activity (you can use the elapsed_time column). Use a combination of the interactive Plotly plot and e.g. the smartphone figure in the beginning of part 2 to make the correct conclusions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer6 = \"\"\"\n",
    "From second X till second Y someone performed Activity Z\n",
    "...\n",
    "\"\"\"\n",
    "print(Answer6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Time Series Feature Engeneering\n",
    "\n",
    "Similar as within the univariate case, we can calculate features from this univarate timeseries. We can calculate featuers for each variable individually (e.g. mean values for x, y & z) but more interesting are features which combine information form multiple variables together. \n",
    "\n",
    "One such feature is the activity index: \n",
    "Given a dataframe with x,y,z accelerometer values, the activity index is the square root of the mean variance over the 3 axis.\n",
    "\n",
    "$$ activity\\_index = \\sqrt{{\\frac {1}{3}}\\sum_{i}^3 Var(channel[i])} $$\n",
    "with channel[i] either x,y or z.\n",
    "\n",
    "**Implement the activity index in the function below. You can use the var function of the numpy package to calculate the variance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_activity_index(dataframe, channels=['x','y','z']):\n",
    "    \"\"\"\n",
    "    Compute activity index of sensor signals.\n",
    "    :param signal_df: dataframe housing desired sensor signals\n",
    "    :param channels: channels of signal to compute activity index\n",
    "    \"\"\"\n",
    "    \n",
    "    activity_index =  # YOUR CODE HERE\n",
    "    \n",
    "    return activity_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, verify that your function works by calculating the activity index for three selected regions in the dataframe above. Use e.g. `df[(df['elapsed_seconds']>30) & (df['elapsed_seconds']<50)]` to select a region with high, medium and a low activity index respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe with only the high activity region\n",
    "high_activity_region = # YOUR CODE HERE\n",
    "high_activity_index = calc_activity_index(high_activity_region)\n",
    "print('The activity index for the selected high activity region is: {}'.format(high_activity_index))\n",
    "\n",
    "\n",
    "\n",
    "# make a dataframe with only the medium activity region\n",
    "medium_activity_region = # YOUR CODE HERE\n",
    "medium_activity_index = calc_activity_index(medium_activity_region)\n",
    "print('The activity index for the selected medium activity region is: {}'.format(medium_activity_index))\n",
    "\n",
    "\n",
    "\n",
    "# make a dataframe with only the low activity region\n",
    "low_activity_region = # YOUR CODE HERE\n",
    "low_activity_index = calc_activity_index(low_activity_region)\n",
    "print('The activity index for the selected low activity region is: {}'.format(low_activity_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this behaviour as expected?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer7 = \"\"\"\n",
    "This behaviour is ...\n",
    "\"\"\"\n",
    "print(Answer7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the activity index could vary over time within our dataframes and it is probably a better idea to calculate the activity index in windows of X seconds.\n",
    "\n",
    "**Calculate the activity index on windows with a frequency of 10 seconds. You will need a UTC timestamp index to select these windows. If you didn't create this timestamp in the past, you can do it here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a utc time index (optional)\n",
    "df['utc_time'] = # YOUR CODE HERE\n",
    "df.index = df['utc_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make groups with frequency 10s\n",
    "ten_seconds_groups = # YOUR CODE HERE\n",
    "\n",
    "# apply the activity index calculation to the windows\n",
    "activity_index_every_ten_seconds = ten_seconds_groups.apply(calc_activity_index)\n",
    "activity_index_every_ten_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activity_index_every_ten_seconds returned every 10 seconds a value. This is actually an univariate time series, created from a multivariate one. We can visualize visualize this univaraite time series. <br>\n",
    "**Make a plot from the activity_index_every_ten_seconds dataframe. You can either use matplotlib code from part 1 or use pltoly code from above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, python packages exists which can generate a large amount of features based on timeseries data.\n",
    "One such common used python package is tsfresh: https://tsfresh.readthedocs.io/en/latest/\n",
    "\n",
    "Take your time to read the quick example of this python package and try to understand the required dataframe representation.\n",
    "\n",
    "Similar to provided example in the documentation, we have a multivariate time series dataframe (X,Y,Z values). \n",
    "We also have a time column to sort our dataframe.\n",
    "What is currently missing, is an id column. \n",
    "\n",
    "We only have only one file, so we could try to create an id column with a constant value here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can apply the tsfresh feature extraction tool to create a large amount of features.<br>\n",
    "*note: to speed up this process, we will only extract features on the first 1000 rows of our dataframe.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[0:1000,:]\n",
    "\n",
    "#note: extract_features is a tsfresh function\n",
    "extracted_features = extract_features(df[['x','y','z','id','time']], column_id=\"id\", column_sort=\"time\")\n",
    "\n",
    "extracted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many features are generated?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_features = # YOUR CODE HERE\n",
    "\n",
    "print(\"tsfresh extracted {} features\".format(nr_of_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be aware that we only have one row with a large amount of features. This means that we generated features for the whole timespan (1000 rows) of the dataframes. This is might not be very interesting. As illustrated before, generating features over a predifned window would be more interesting. **Therefore, one can manipulate the id column to represent the windows. Values belonging to the same window should have the same id.**\n",
    "\n",
    "**Calculate tsfresh features for each 10s window. Take a look at the ngroup() groupby function as this will help you to identify the 'id' column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new ID for each window of 10s, take a look at the ngroup function\n",
    "df['id'] = df.groupby(pd.Grouper(freq='10s')).ngroup()\n",
    "\n",
    "extracted_features = # YOUR CODE HERE\n",
    "\n",
    "extracted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For how many windows did we generate features? (keep in mind that we only generated features for the first 1000 rows of the original signal)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_windows = # YOUR CODE HERE\n",
    "\n",
    "print(\"tsfresh extracted features for {} windows.\".format(nr_of_windows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all features discriminate the different windows. Especially the features which share similar values in each windows are less of interest. **Remove the columns from the extracted_features dataframe where all the values in these columns are the same. How many interesting features to we keep?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of unique values in each column (you can use the nunique pandas function)\n",
    "nunique = # YOUR CODE HERE\n",
    "\n",
    "#select the columns for which the nunique values are equal to the amount of rows (all have the same value)\n",
    "# YOUR CODE HERE, CHANGE NONE\n",
    "cols_to_drop = nunique[nunique==None].index\n",
    "\n",
    "\n",
    "#drop these columns from our dataframe.\n",
    "extracted_features = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_unique_values = # YOUR CODE HERE\n",
    "\n",
    "print(\"After removing the columns which have unique values in all the rows, we keep {} features\".format(nr_of_unique_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of lab\n",
    "---\n",
    "\n",
    "In this lab, you had in introduction about time series analysis.<br>\n",
    "you analysed both univariate and multivariate signals, created features both manually and by using python packages and used plots to understand and visualize the obtained signals.\n",
    "\n",
    "Make sure you provided your name in the first cell of this practicum and **Zip** your lab assignment folder and name the archive: `Surname_Name.zip` <br> Keep the same folder structure as the provided lab assignment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
